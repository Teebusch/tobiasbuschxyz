[
  {
    "path": "posts/2020-02-20-a-walk-in-the-park/",
    "title": "A Walk in the Park",
    "description": "The beginning of my D3 journey was a walk in the park.",
    "author": [
      {
        "name": "Tobias Busch",
        "url": {}
      }
    ],
    "date": "2020-02-22",
    "categories": [
      "D3.js",
      "R",
      "datavis"
    ],
    "contents": "\r\n\r\nContents\r\nA First Look at the Data\r\nDuration of Visit\r\nMovements and Check-Ins\r\nDifferences between days\r\nPaths\r\n\r\nUnderstanding the Data Structure - Who, When, Where, What?\r\nLocations and Attractions\r\nVisitors\r\n\r\nVisualization Sketches\r\nFinal Visualization Sketches\r\nCrooked Paths — Visualizing Visitor’s paths\r\nFlagging “Mutations” in visitor DNA\r\nVisualizing Visitors at Rides: Overview\r\nVisualizing Visitors at Rides: Details\r\n\r\nPreparing Data for the Visualization\r\nSketching in R – Crooked Paths\r\nSketching in R – Coming and Going\r\nAdding Interactivity\r\n\r\nFinal Visualization with D3.js\r\nConcept\r\nImplementation\r\nLimitations\r\n\r\n\r\nIn 2018, I took a semester-long course on data visualization at KU Leuven. It was a course from the statistics Master’s program, taught by Prof. Jan Aerts. The class was project-based and had less than a dozen students and 3 TAs, so it was an intense and hands-on learning experience. We worked with a fairly large data set–more than 1 GB of data–of people’s movements around an amusement park and were free to find our own approach to visualising it.\r\nProject\r\nTry the final interactive visualization at teebusch.github.io/park-vis (please allow some time for it to load)\r\nIn class we used P5.js - a Java Script implementation of the Processing language. However, after some sketching and data exploration with R and some prototyping with Shiny, I decided to use D3.js to build the final visualisation. It was a great opportunity to take a deep dive into D3, and I learned quite a lot.\r\nFor the course I documented my design process as a series of posts on Medium. I’ve copied them all here and you can find them below.\r\nA First Look at the Data\r\nThe assignments revolve around a data set of visitor movements in a theme park. In this (simulated) theme park, each visitor’s position is captured once a second. When they check in at a location, this is captured, too. We work with the visitor data from one weekend–Friday to Sunday. There are over 26 million records in the data set, from 3500 (Friday) to 7500 (Sunday) unique visitors per day. There is also evidence of a mysterious crime in the data, but that’s for another blog post. The first assignment is to explore the data. Here are some of my insights and thoughts on the data…\r\nDuration of Visit\r\nMost visitors arrived before 10am and 75% of visitors stayed for at least 12 hours. The longest stay was just short of 15 hours (which is almost the maximum, given the opening hours, 8am to 11.30pm). The shortest stay was just 10 minutes long (what happened there?).\r\n\r\n\r\n\r\nFigure 1: The (simulated) theme park. Check-in locations are marked by numbers.\r\n\r\n\r\n\r\nMovements and Check-Ins\r\nThe park has a number of locations at which visitors can “check in”. Many of these are rides (such as rollercoasters). An average visitor checks in at around 20 locations. It seems that on the day where the least visitors came to the park, Friday, the average number of check-ins was higher (23) than on Saturday and Sunday (17 and 18, respectively). There are a few visitors with just a single check-in–their entry into the park?–and two with 61 check-ins. The average number of unique locations a visitor checks in at is 12–15. Once they check-in at a location, visitors stay for around 7 minutes (Median).\r\nWe can plot the accumulated time that visitors have spent in each 5x5 meter grid of the park (“movements”) and at each check-in location.\r\n\r\n\r\n\r\nFigure 2: Accumulated time spent on each 5x5 meter grid (square-root). Circles indicate check-in locations, diameter indicates time spent in the location.\r\n\r\n\r\n\r\nAlthough the plot does not show whether there are more people in a given area, or people just stay longer, it’s obvious that not all areas are equally frequented. This may be the case because there is a a foodcourt, a resting space, or a particularly fun-to-watch attraction. Visitors don’t necessarily spend more time in a spot because they want to. Congested areas are just harder to pass through.\r\nLooking at this I wonder…\r\nDo people move slower on days/times when there are more visitors? Do they move slower when there are many other people close-by?\r\nAre there areas where movements are particularly slow? If so, why?\r\nIt’s also clear that some check-in locations are more popular than others. Some interesting question come to mind:\r\nWhich locations are the most popular? At different times of the day? At different “phases” of the visit? For shorter / longer visits?\r\nWhich rides are taken multiple times by the same person? Are they taken consecutively? Throughout the day?\r\nDo people take longer at a check-in location depending on the number of visitors in the park / the number of visitors that are close-by? That is, can we see waiting times change?\r\nAre there locations that people skip more than others, i.e. where people walk by without checking in? Does the “skip-rate” depend on the number of visitors queueing for it, the time of the day…?\r\nHow many people does each location “service” per unit time?\r\nAt which rate does each visitor check in to rides. Do people get slower/faster over time? Do some people have a higher frequency than others?\r\nDifferences between days\r\nWe can also plot the most frequented areas and check-in locations for each day and time. I don’t see any striking irregularities on any of the days. This is a bit unexpected, since there was a major incident in the park on one of the days, and I would expect this to be visible. I may be looking at the data in the wrong way.\r\n\r\n\r\n\r\nFigure 3: Top 30% of areas and locations (circles) per day (top to bottom: Friday, Saturday, Sunday) and two-hour interval (left to right: 8–10am, 10am–12pm, …).\r\n\r\n\r\n\r\nPaths\r\nIf we plot some individual visitors’ path through the park we can see that there are typical patterns as well as individual differences.\r\n\r\n\r\n\r\nFigure 4: Paths of 30 random visitors through the park. Shade of blue indicate time of the day, pink dots indicate check-ins.\r\n\r\n\r\n\r\nAgain, some questions come to mind:\r\nWhat does the typical “flow” of visitors through the park look like? Do people just go through the rides in the order they encounter them or do they\r\ntake more complex paths? Are there particularly common sequences?\r\nDoes it make sense to model check-in sequences as Markov chains, or check-in\r\nfrequencies as Poisson distributed, so we can identify unusual behaviour?\r\nAre there peak times throughout the day? At particular rides?\r\nCan we identify people who move in groups? Does group size affect behaviour (number of rides taken, duration of pauses, length of stay)? If groups split, why, for how long, and where do they reunite?\r\nAre there clusters regarding which areas of the park people go to? E.g. rollercoaster-maniacs, water-freaks, foodcourt-chillers, families hanging out in kiddie-land all day…?\r\nCan we see people resting? When and where do visitors rest?\r\nThis is a simulated data set, so not all of these questions may have interesting answers, but it will still be fun to investigate them further. I’m running of time, so I will have to leave them open for now.\r\nUnderstanding the Data Structure - Who, When, Where, What?\r\nThe next step towards visualizing the park data is to specify the “data structure”. In the Methodical Exploration of Design Space (MEDS) framework, this exercise helps to expand the “Design space that you know” to cover more of the “Design space that exists”.\r\nIn computer science different data structures lend themselves to different operations: Elements in an array can be accessed directly via their index, but removing a random element is computationally expensive. Elements of a linked list can be removed easily, but to find the nth element, one must visit all n-1 preceeding elements. Although the two concepts are not identical, identifying the data structure of the park data set should in a similar way help to reveal units of observation, relationships, derivative variables, and possible operations.\r\nMy starting point for figuring out the data structure was to think about the available observational units and their features. Then I sketched the data structure. I tried to incorporate the aspects I had thought about, while keeping an open mind for connections my brain would make as I was drawing. Here’s what came out of that:\r\nLocations and Attractions\r\nLocations are small parts of the park (5x5m tiles). Each tile has up to eight neighbouring tiles. Not all xy-coordinates represent accessible tiles, but all accessible tiles are connected. One can find the shortest path between any two locations (finding the longest path is not as easy). Moving from one location to another will take some amount of time and likely depends on factors such as the number of visitors in the location, the direction one is heading, the speed at which one is moving…). There will be some number of visitors at a location at any time.\r\nSome locations are attractions that visitors check into, spend time at, and then leave again. Attractions belong to certain categories (water slides, thrill rides, stage shows…), that will make them more or less attractive to different visitors. Even within a category their popularity may vary. At a given moment in time, there will be some number of visitors checked in at an attraction.\r\nUsing an attraction will normally take a more or less constant amount of time. However, attractions can only serve a certain number of visitors per unit time. If that number is exceeded, visitors will have to queue, i.e. spend more time “checked-in”, or even wait outside, not checked in.\r\nAttractions may be closed down and inaccessible to visitors during certain times, like when there is no show at a stage (…or after a horrendous crime!). Since attractions are also locations, the same concepts of distance and “moving between them” apply. Attractions can be more or less similar in terms of location, opening hours, time it takes to use them, category, and popularity.\r\nNotably, there could be locations where people do not have to check-in but which they still seek out intentionally and for longer times, such as restrooms and food courts.\r\n\r\n\r\n\r\nFigure 5: An early design sketch\r\n\r\n\r\n\r\nVisitors\r\nVisitors enter the park, spend some amount of time there, then leave again. During their visit they move between locations more or less quickly, and check-in at any number of attractions (possibly multiple times) in a self-determined order. They will sometimes pass by certain attractions without checking in. The attractions they visit (or not visit) and the paths they take may be more or less similar, and can help identify different types of visitors. Visitors will often arrive and move in groups, that split and reunite, and they may return on multiple days (although I’m not sure if that would actually be tracked). They may spend some time neither moving nor checked-in anywhere (i.e. resting).\r\nFor visitors it makes sense to look for patterns related to their visiting time** in addition to clock time. That is, how much time has passed since they entered the park. For example, visitors could be getting slower and less active towards the end of their visit, or build the courage to try out the more daring rides.\r\n\r\n\r\n\r\nFigure 6: An early design sketch\r\n\r\n\r\n\r\nVisualization Sketches\r\nThe next step to visualizing the park data is to make some sketches of possible visualizations. The point is to do a lot of them, fast, and without being too critical (at least for now). I found it quite difficult to move from idea to idea quickly. Mike Bostock’s talk on design as a search problem was mentioned in the class — I’m definitely more of a depth-first searcher by nature. I see the point of being more breadth-first, though, and it’s fun to try to push myself into that direction (albeit not yet very succesfully).\r\nI didn’t bother to sketch any of the more obvious visualizations (e.g. bar plots of visitor numbers…) because I find the less simple visualizations more intriguing and I really hope to do something unusual for this course. This could be a mistake, because sometimes the more interesting ideas are easier to get to if you approach them in little steps. This is something I noticed when doing this exercise, and it was also mentioned in the course and in Bostock’s talk, I believe. Then again, there is only so much time I can spare.\r\nI also didn’t bother with sketching maps, because I have already visualized the maps for the first blog post and I don’t really want to make a “geographical” visualization for the project. I find the exact location more of a nuisance variable that adds noise to the truly interesting information. I’d rather “abstract it away” somehow, and I explored some ways to do this (e.g. by using “transitional probabilities” between locations).\r\nAnyways, enough talk. Here are my sketches:\r\n\r\n\r\n\r\nFigure 7: This was more of a reminder of what the data structure could look like than a visualization sketch.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 8: Some simple plots that show the average hourly visitor numbers (or some other attraction-related statistic of choice) for all attractions in the park, color-coding different areas. I’m surely using too many circles in all my sketches. It looks nicer, but a bar plot would likely be better in many cases.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 9: Top left: for all attractions, which other attractions did the visitors go to? Top right: I was trying to wrap my head around the three different ways that visitors interact with attractions in the park. Not really a visualization sketch. Bottom: For each attraction, how many people passed by, checked in, never went there?\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 10: Left (orange): can we show a visitors path through the park and contrast it against other wisitors paths? Right: I realized that for any two visitors check-in/no-check-in profile, we can define the Hamming distance. This means we can find identical profiles, profiles with 1 (2, 3, … n) differences.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 11: Here I’m mostly expanding on the idea with the Hamming distance. Can we show the way that other almost identical visitors are different. Might be a good way to detect unusual patterns.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 12: Between any two check-in locations there is a transitional probability (and for longer sequences of check-in locations we could define the n-gram probability using Markov chains). Can we use this to find people who take very uncommon paths through the park?\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 13: I was trying to find a way to show when people check into a location, how many check in, and for how long they stay. I first tried some fancy glyphs (the angular and toilet brush shaped things). But in the end I found the scatter plot with bars (bottom right) the clearest way to do it.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 14: Top: This is similar to some of the previous sketches. we can show how many people travel between any two locations, in which direction, and how long they take (relative to each other). Bottom right: The line shows the path between two locations. On the way there may be other locations (smaller black bars). The size of these show how many (proportion) of the people who went from A to B stopped at that inbetween location. Instead of circles little squares / bars could work well for this. Showing the path (line).\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 15: Most of this is similar to the bottom right one above. There is a reference location (marked with 100%). We want to know which other locations the visitors of this reference attraction have visited (or not visited!). The idea is similar to Amazon’s ‘Customers who bought this also bought…’, but it’s also showin you how many of them did so.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 16: Here I played with the idea of river plots (I believe that’s what they are called). They show the flow of visitors to and from the reference location. You can see which attractions they come from, and where they go afterwards. We could plot just the previous and next steps of their journey (top right), or multiple steps (top left).\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 17: Left: continuation of above. Right: Maybe someone can explain to me what I was trying to do here?\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 18: These are mostly variations on ideas I’ve already sketched elsewhere.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 19: I was trying to show where in the park visitors are, and how that changes throughout the day. I am a bit fond of the ‘solar system’ idea in the bottom left. It’s a circular bar plot, where each circle is an attraction and the bars show the number of visitors around the clock. The larger a circle, the more visitors in total.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 20: The top left shows a visitors’ path from location to location. the horizontal distance is the time they traveled, the vertical distance is the distance thy traveled. Both could be normalized to the expected (e.g. average) time/distance for traveling between the two locations. The bottom one is similar to the area plot in the previous sketch.\r\n\r\n\r\n\r\nFinal Visualization Sketches\r\nThis week’s assignement for the visualization course was to make a final round of paper sketches.\r\nCrooked Paths — Visualizing Visitor’s paths\r\nThe idea is to show individual visitors’ paths in a way that makes unusual paths easy to spot (i.e. making it a relatively simple “perceptual task”). I thought that transitional probabilities could be the key to such a visualization. Transitional probabilities can be assigned to the the transition between any two check-in locations, based on the number of visitors checking in at them in that order, p(B|A), relative to those who instead go to another location, p(not B|A). By translating the probability of transitions between check-ins into angles, unlikely paths will appear crooked.\r\nPaths can be sorted according to their crookedness, too. Other types of clustering can be used, as well, e.g. based on Hamming distance (see below). Clusters could also be shown separately, and transitional probabilities could be calculated per cluster rather than overall.\r\n\r\n\r\n\r\nFigure 21: Hovering should highligh an individual path. When a path is selected, additional detail / plots for this visitor can be displayed (not shown).\r\n\r\n\r\n\r\nInstead of length of all paths being equal, one could encode other information in the length, such as the time it took to travel between the location or the distance traveled. Alternatively, keeping each individual check-in segment at the same length, people who have more checkins will stand out more. Filtering (or highlighting) by length is also an option and could be realized with simple mouse interactions (e.g. horizontal position of the mouse filters paths of certain lenghts).\r\nAlternatively, probability of transitions could be encoded in the width of the line, as shown below. This might have the advantage that paths will not overlap. However, I have a feeling that the option above is visually more appealing, and I like the analogy with “crooked paths”.\r\n\r\n\r\n\r\nThe idea could be extended using the probabilities of longer chains, i.e. n-grams / Markov chains, rather than simple transitional probabilites between two locations (i.e. 1-grams). For a first atempt, this seems unnecessary.\r\nFlagging “Mutations” in visitor DNA\r\nAs shown in a previous blog post, we can divide a visitors path into visited and unvisited locations — basically a vector of 0’s and 1’s. For each visitor we can then find visitors who have the same vector except for one location (a Hamming distance of 1). This information can be used to see with regards to which locations a visitors path stands out from the rest.\r\nThe Hamming distance can also be used for clustering visitors, which could be useful to add some order / filtering to the plots (including the rooked paths plot above).\r\n\r\n\r\n\r\nFigure 22: Instead of highlighting ‘unusual’ check-in locations, one could just color code the number of check-ins at that location. Some visitors may stand out quite a bit if we do that.\r\n\r\n\r\n\r\nVisualizing Visitors at Rides: Overview\r\nThe main goal of visualizing rides is to detect (unusual) patterns of visitors coming and going.\r\nOne useful plot would be some sort of overview of all locations over time. I don’t like to show the locations and paths on a map, because their exact geographic location seems irrelevant, and maps leave a lot of unused negative space. Instead I was thinking of arranging them as tiles (see below), rougly sorted by proximity. Then changes in time can be visualized as sort of a heatmap.\r\nThe paths between locations can be summarized as tiles as well, because we always know where people are coming from and where they are heading to, i.e. which path they are on.\r\n\r\n\r\n\r\nInstead of using a grid, one could lay out the locations/paths in a slightly less rigid way that still reflects geographial proximity or some other kind of similarity. This allows other ways of encoding information besides hue/saturation:\r\n\r\n\r\n\r\nFigure 23: The locations are represented as lines. The Visitor activity is coded as ares, which is slightly more salient than hue/saturation used in the heatmap above.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 24: Clusters of attractions are shown as circles made of circles, like a pearl necklace. The size of the large (necklace) and small (pearls) changes as a result of visitor activity. If nothing is highlighted it will look like a long motion blur / multiple exposure and should give an idea of the overall change. By using the mouse, individual moments in time can be highlighted.\r\n\r\n\r\n\r\nVisualizing Visitors at Rides: Details\r\nFor a more detailed view of the activity at the rides it should be possible to work with small multiples. There are three plots I thought could be useful:\r\nThe top one shows the number of vistors and the duration of their stay throughout the day(s)\r\nThe midle one shows how many visitors check-in at each time. Different sizes for the rolling average window are displayed at the same time to allow the detection of long term patterns and short term patterns.\r\nThe botom plot shows where visitors are coming from and going to at each moment in time. By adding some simple interactivity one could find times where unusual things are happening. This likely is too complex or small multiples, but it’s definitely somethin I’d like to try.\r\n\r\n\r\n\r\nThe plot below shows where else the visitors from a certain ride are also going (and how far these locations are from it). To some extend this could be incorporated in the third plot above.\r\n\r\n\r\n\r\nThese are some ideas I definitely want to try out. There are some simpler plots (histograms and the like) that could be added around them to add more information.\r\nPreparing Data for the Visualization\r\n\r\n\r\n\r\nFigure 25: The check-in locations in the park with the IDs and categories corresponding to the the map. Note that not all locations can be checked in to (cf. full list of categories on the right).\r\n\r\n\r\n\r\nTo prepare the park data for the visualization some data preparation is necessary. One thing I have done is to figure out the IDs, names and categories of all check-in locations. I also made a distance matrix for walking distance between all check-in locations and some smaller things.\r\nI thought that some of it could be useful to other course participants, so I’ve put the code on Github. Instructions and details can be found there. The code is heavily commented, but if there are any questions, I’d be happy to help. Also if anything seems odd, let me know and I will check it. It’s not unlikely that I made a mistake (it should also go without saying that this is “use at your own risk”).\r\nSketching in R – Crooked Paths\r\nI tried to build some of the visualizations I had in mind for the park data in R. With ggplot it’s easy to try out ideas quickly and detect problems. I started with the crooked paths visualization, in which the “regularity” of each visitor’s path through the park is shown, so that unusual paths can be detected. For this I calculated transitional probabilities for each sequence of two check-ins (How likely is it that someone checks in at location B after they visited A?). These probabilities are normalized for each check-in location and translated into an angle (0–180 degree) and a hue. The brighter and more “downward pointing” a line segment is, the lower the transitional probability.\r\nThere are over 17.000 paths in the data set, so some kind of filtering or faceting is needed. For now I’ve split the paths by the number of check-ins. I also randomly sampled 3000 visitors to spare my laptop some pain. Here’s what the sketch looks like:\r\n\r\n\r\n\r\nIt’s obvious that showing too many paths at the same time will not work. In the actual visualization the number of paths shown should be limited through some kind of filtering.\r\nIn the plot below I’m showing just 200 paths divided over different buckets. The further to the right a line segment points, the lower the transitional probability. The small number works much better for detecting interesting paths. It’s still quite crowded, though, and interactivity with brushing and highlighting will be key to make this work.\r\n\r\n\r\n\r\nOne way to make it easier to spot strange paths is to offset the individual path’s starting points a bit, and sort them according to their “crookedness”. This can be seen below. In this case I’m sorting them by their average displacement. The nice thing about this is that the line ends (white dots) double as a scatter plot with the “crookedness” mapped on the horizontal axis and the length of the path on the vertical axis. This can help to spot ouliers (say, short but very crooked paths).\r\n\r\n\r\n\r\nInstead of allowing the paths to “recover” from their crookedness, we can also accumulate it. For every unusual transition, the path gets slightly more bent to the right. This gives us a plot like the one below.\r\n\r\n\r\n\r\nIn general, I am not 100% satisfied with this idea. It looks visually pleasing and it could help to detect some outliers, but it does not accomodate the many data points and it does not work great as a data display. I’m sure it can still be improved, and I will think about how to do that.\r\nSketching in R – Coming and Going\r\nHere’s another visualization of the park data I’m working on. It shows people checking in and leaving different locations. Each subplot is one location. Every line represents a visitor entering (lines on top) or leaving it (lines on bottom). The small circles in the center indicate the number of checked in visitors per 15 minute time window. The hue shows how long the visitors stay.\r\n\r\n\r\n\r\nFigure 26: Visitors entering and leaving different locations on Friday. It looks a bit like hair color samples. (Note: the dots in the center don’t work as they are supposed to, yet, but it’s just a sketch anyways.)\r\n\r\n\r\n\r\nIt’s possible to spot patterns and differences between locations. See for example the SabreTooth Theatre (2nd row from the bottom, 2nd plot from the left): people are entering almost continuously, but leaving in large groups in regular intervals. I imagine people wait around for the show to begin and then leave quickly once it is over. A similar pattern can be seen for the Scholtz Express (two to the right) — probably a train that takes in a large group of people at a time and spits them out ~10 minutes later.\r\nHowever, there is a lot of fine tuning needed to really make this visualization work:\r\nThe hue doesn’t work that well, because the distribution of the duration is heavily right-skewed. Some transformation might help. However the lines being translucent and overlaying each other also muddles the color-coding.\r\nThe dots in the center overlap too much. It’s not really possible to read any useful information from them. As an alternative I put a bar plot in the center (see below). This works better to show the summary data, but obscures the line endings a lot. Maybe it is something for the detail view?\r\nThe plot takes a few minutes to draw. It’s a lot of data (more than 16.000 curves for Friday alone). As an svg file it is almost 200 Mb large. That means that some compromise is necessary to make this work as an interactive visualization. There are lots of overlapping lines — maybe it’s possible to reduce or summarize them?\r\nThe subplots are arranged haphazardly. Arranging them by location- category, total number of visitors, proximity or similar would make sense.\r\n\r\n\r\n\r\nFigure 27: The same ‘glyph’, but with bars rather than dots in the center. The top row indicates number of checked in visitors, the bottom row indicates median duration of stay. (Yes, the color scales of the lines and the bars don’t match.)\r\n\r\n\r\n\r\nAdding Interactivity\r\nA plot with small multiples like the one above serves as a good overview. Selecting an individual location could then reveal a detailed view.\r\nIn the detail view the visitors’ lines could be separated by where they are coming from and going to. The user could then choose to highlight all connections with specific locations by hovering over the points in the center or at the edges. One could then, for example, see which ride people are coming from when they check into Liggement Fix-Me-Up (the medical station, I presume). This could tell us which rides cause the most injuries. A static version of the detail plot can be seen below:\r\n\r\n\r\n\r\nThere are some improvements that can be made to the detail plot:\r\nMake it interactive\r\nPosition, sort, size and color the dots at the top and bottom to show the location’s category, total contribution of visitors, proximity to each other, or distance to the selected location. Of course the dots should also be labeled.\r\nAgain, it takes quite long to draw the plot. Not as long as for the plot above, but likely too long to make the interaction feel smooth.\r\nCurrently, there is no location id for “not in the park”. I believe the rows where people just entered the park or leave it afterwards are simply being dropped (not shown) by ggplot. This must be fixed.\r\nI’m much happier with this visualization than with the crooked paths. It looks nice, works good for detecting patterns and can pack a lot of information. The main challenge will be to make this interactive.\r\nFinal Visualization with D3.js\r\nHere’s the final result. You can try it yourself at https://teebusch.github.io/park-vis/.\r\nYou can also inspect the source code (including all the R code for data munging and sketching) on Github.\r\nWe worked with a data set of visitor movements through a (simulated) amusement park. Over the course of a weekend each visitor’s position in the park and their use of the various attractions (rides, shows etc.) was tracked. There are more than 26 million records. The data contains traces of disturbances in park operations and interesting patterns for us to discover.\r\n\r\n\r\n\r\nWe had to go through all the steps of defining and implementing a visualization project. The goal of the assignment was open-ended. A personal goal of mine was to get more into D3.js and create a customized, truly interactive data visualizations.\r\nConcept\r\nAfter multiple rounds of sketching on paper and in R I decided to visualize the visitor flow between the different attractions in the park, and the way it changes over time. The visualization should not lead up to a single conclusion but rather allow the user to explore the data freely, while making it easy to spot unusual events and patterns. A visualization like this could be useful, for example, for park management.\r\nImplementation\r\nWhen I used R to implement my idea with real data, it became clear that there were some interesting patterns. However, for the visualization to really work, the interface had to be more responsive and interactive than what ggplot and Shiny could do — D3 to the rescue!\r\nA while ago I had read Scott Murray’s “Interactive Data Visualization for the Web” and followed a beginner’s D3 course on Lynda.com. To get a more in-depth understanding of D3 I picked up Elijah Meeks’ “D3.js in Action”.\r\nSome examples of insights gained from the visualization are provided in the figures below.\r\n\r\n\r\n\r\nFigure 28: Total number of visitors in park and at Grinosaurus stage throughout the 3 days. It’s easy to see that the second one of the bi-daily show did not take place on Sunday. Also: the second show on both Friday and Sunday seems to be more popular, even though the number of visitors in the park is the same.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 29: Example: Visitor flow to/from Liggement Fix-Me-Up. Most people who need ‘fixing up’ come from the Firefall and Atmosfear thrill rides. Interestingly, most people who have just been fixed up go right back to one of the thrill rides. There also seems to be a strong peak in accidents on Friday.\r\n\r\n\r\n\r\nLimitations\r\nDue to time constraints and the steep learning curve of D3, some features could not be implemented before the submission deadline of the asgignment. Most unfortunately, the final implementation does not contain a “small multiples” view of all locations with their visitor number and check-in durations, as sketched in R. This would be a very useful addition to the interface, to help the user get an overview before “drilling down”. Legends for heat maps and circle sizes are missing, too.\r\nHowever, I won’t add to it anymore. I’ve learned a lot doing this project, but there is a diminishing return. There’s a lot more to learn about designing and implementing visualizations. In particular the early sketching and conceptualizing – getting from a data set to a visualization idea – is something that needs a lot of practice. It’s better to look for a new challenge.\r\nDo you like the visualization? Did it make you hungry for a plate of colorful spaghetti? Tell me about it! [@drtobilotti](https://twitter.com/drtobilotti)\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-02-20-a-walk-in-the-park/./images/screenshot.png",
    "last_modified": "2020-10-30T00:09:28+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-02-15-theres-a-package-for-that-2/",
    "title": "Making gaps in axes with ggplot2",
    "description": "Because sometimes less is more.",
    "author": [],
    "date": "2020-02-15",
    "categories": [
      "R-for-everything",
      "R",
      "data-vis"
    ],
    "contents": "\r\n\r\nContents\r\nMind the Gap!\r\nCapped axis\r\nBracketed axes\r\nDiscontinuous axes\r\n\r\n\r\n\r\n\r\nThere’s an R package for that!\r\nThere are over 15.000 packages on CRAN, the R package repository, and many more on GitHub and other places. Some will make your life easier, some will make you scratch your head in wonder. In this series of blog posts we have a look around the R package ecosystem. Each episode highlights another package, demonstrating the power of R and its amazing community.\r\nMind the Gap!\r\nIf you want to add a gap to a figure’s axis, you are probably looking for one of three things:\r\nCapped axes – Look good when using continuous variables that don’t start at 0.\r\nBracketed axes – Look nice when plotting discrete variables.\r\nDiscontinuous axes – Good for showing outliers without squishing all other data.\r\nCapped axis\r\nHere’s a simple plot, using ggplot and theme_classic()\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\nif(!require(gapminder)) install.packages(\"gapminder\")\r\ndata(gapminder, package = \"gapminder\")\r\n\r\ndf <- gapminder %>% \r\n  filter(continent == \"Europe\", year == 2007)\r\n\r\np <- df %>% \r\n  ggplot(aes(gdpPercap, lifeExp)) +\r\n  geom_point() +\r\n  labs(\r\n    x = \"GDP per capita\", \r\n    y = \"Life Expextancy (years)\", \r\n    title = \"Average Life Expectancy in European countries, 2007\",\r\n    subtitle = \"source: Gapminder data\"\r\n  ) +\r\n  theme_classic()\r\n\r\np\r\n\r\n\r\n\r\n\r\nFigure 1: a ggplot figure with the classic theme\r\n\r\n\r\n\r\nI’d argue that the joint axis lines at the origin (i.e., in the corner on the bottom left) are not great: The two scales (GDP and Life Expectancy) are measured in very different units, and the values do not include zero. Indeed, the fact that the values are far from zero already tells us something about life in Europe, so why don’t we highlight this more?\r\nUnfortunately, ggplot does not come with a theme where the axis lines are not joined at the origin. Luckily for us, there’s lemon – “a package to freshen up your ggplots!”. Here’s how it works:\r\n\r\n\r\nif(!require(lemon)) install.packages(\"lemon\")\r\nlibrary(lemon)\r\n\r\np + lemon::coord_capped_cart(bottom = 'both', left = 'both')\r\n\r\n\r\n\r\n\r\nFigure 2: a ggplot figure with capped axes\r\n\r\n\r\n\r\nBy default, the axes may be capped at a weird point. For more control, you can specify the axis ticks manually:\r\n\r\n\r\np + \r\n  lemon::coord_capped_cart(bottom = 'both', left = 'both') +\r\n  scale_x_continuous(\r\n    breaks = seq(5000, 50000, 5000), \r\n    labels = scales::label_number_si()\r\n  )\r\n\r\n\r\n\r\n\r\nFigure 3: a ggplot figure with capped axes and custom tick marks\r\n\r\n\r\n\r\nNote: You have to get rid of the panel border and axis lines to see the effect. If you are not using theme_classic() this can be achieved by adjusting the theme of the plot like this…\r\n\r\n\r\np + \r\ntheme(\r\n  panel.border = element_blank(),\r\n  axis.line    = element_line()\r\n)\r\n\r\n\r\n\r\n\r\nBracketed axes\r\nYou can also use lemon to make bracketed axes. These look good when you are plotting discrete variables. So instead of this…\r\n\r\n\r\ndf <- gapminder %>%\r\n  filter(year == 2007)\r\n\r\np <- df %>% \r\n  ggplot(aes(continent, gdpPercap)) + \r\n  geom_jitter(width = 0.15, shape = 1) + \r\n  scale_y_continuous(label = scales::label_number_si()) +\r\n  labs(title = \"GDP per Continent, 2007\", x = \"Continent\", y = \"GDP per capita\") +\r\n  theme_classic()\r\n\r\np\r\n\r\n\r\n\r\n\r\nFigure 4: a ggplot figure with the classic theme\r\n\r\n\r\n\r\n…you get this:\r\n\r\n\r\np +\r\n  lemon::coord_flex_cart(bottom = brackets_horisontal(), left = capped_vertical('both')) +\r\n  theme(\r\n    axis.text.x  = element_text(vjust = -1),  # the labels are a bit too close to the brackets\r\n    axis.title.x = element_text(vjust = -2)\r\n  )\r\n\r\n\r\n\r\n\r\nFigure 5: a ggplot figure with bracketed axes\r\n\r\n\r\n\r\nThe bracketing helps to emphasise that the variable on the x-axis (continent) is a discrete variable, and to visually separate the jittered points belonging to each continent.\r\nYou can learn more about lemon here. For an alternative solution using ggplot-trickery, see this Stackoverflow answer.\r\nDiscontinuous axes\r\nSo far we have only removed parts of the axis lines, leaving the data points where they are in the figure. Sometimes we’d like to skip sections of the coordinate system, for example to show outliers without having to squish together all other data points. To demonstrate this, I will add an outlier to the data:\r\n\r\n\r\ndf <- gapminder %>% \r\n  filter(continent == \"Europe\", year == 2007) %>% \r\n  add_case(country = \"Shangri-La\", gdpPercap = 10000, lifeExp = 245)\r\n\r\np <- df %>% \r\n  ggplot(aes(gdpPercap, lifeExp)) +\r\n  geom_point() +\r\n  labs(\r\n    x = \"GDP per capita\", \r\n    y = \"Life Expextancy (years)\"\r\n  ) + \r\n  theme_classic()\r\n\r\np \r\n\r\n\r\n\r\n\r\nFigure 6: a ggplot figure with an extreme outlier on the y axis\r\n\r\n\r\n\r\nThis is bad! The outlier makes it very difficult to tell the difference in life expectancy between all the other data points. In a case like this, a log-transformation can often help to stretch out the data points with lower values while bringing those with higher values closer to them. Here a log-transformation would not help much and it would make the units harder to interpret – log life expectancy in years instead of life expectancy in years.\r\nInstead, it might be better to skip a range of values along the axis. You just have to make sure that the reader understands that this is what you are doing, so you don’t unintentionally mislead them.\r\nTo skip a range of values on the y-axis you can use the gg.gap package, which you can find on CRAN and here. It works like this:\r\n\r\n\r\nif(!require(gg.gap)) install.packages(\"gg.gap\")\r\nlibrary(gg.gap)\r\n\r\n# we need to tweak the theme a bit to make it look nice\r\n# and we need to do it before we pass the plot to gg.gap\r\np <- p +\r\n  theme(\r\n    panel.background = element_rect(fill = \"white\"), \r\n    panel.grid = element_blank(),\r\n    axis.line = element_blank()\r\n  )\r\n\r\np %>% \r\n  gg.gap::gg.gap(\r\n    ylim = c(65, 250), \r\n    segments = list(c(85, 240)),\r\n    tick_width = 5,\r\n    c(0.7,0,0.3)\r\n  )\r\n\r\n\r\n\r\n\r\nFigure 7: a ggplot figure with a gap on the y axis\r\n\r\n\r\n\r\nTo me, gg.gap feels a bit fiddly and the documentation is not very clear. If you don’t mind using base R graphics instead (thus, losing the power of the grammar of graphics), the plotrix package might offer a better alternative:\r\n\r\n\r\nif(!require(plotrix)) install.packages(\"plotrix\")\r\nlibrary(plotrix)\r\n\r\nplotrix::gap.plot(\r\n  x = df$gdpPercap, \r\n  y = df$lifeExp, \r\n  gap = c(87, 243), \r\n  breakcol = \"white\", \r\n  xlab = \"GDP per capita\", \r\n  ylab = \"life Expectancy\",\r\n  ytics = c(70, 75, 80, 85, 245),\r\n  ylim = c(68, 247)\r\n)\r\n\r\n# decorate the gaps with diagonal slashes\r\nplotrix::axis.break(2, 87.2, breakcol=\"black\", style=\"slash\")\r\nplotrix::axis.break(4, 87.2, breakcol=\"black\", style=\"slash\")\r\n\r\n\r\n\r\n\r\nFigure 8: a r base graphics figure with a gap on the y axes\r\n\r\n\r\n\r\nHas this blog post helped you? Do you know other packages that remove things which don’t spark joy? Tell me about it! [@drtobilotti](https://twitter.com/drtobilotti)\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-02-15-theres-a-package-for-that-2/./images/hero.jpg",
    "last_modified": "2020-11-05T23:42:39+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-01-11-theres-a-package-for-that-1/",
    "title": "Making noise with beepr and BRRR",
    "description": "Some R packages will make your computer scream. Quite literally.",
    "author": [],
    "date": "2020-01-11",
    "categories": [
      "R-for-everything",
      "R"
    ],
    "contents": "\r\n\r\nContents\r\nMake R scream with “beepr”\r\nMake a Pomodoro timer with beepr\r\n\r\nPlay rapper ad-libs with “BRRR”\r\nLook ma, no hands!\r\n\r\n\r\n\r\n\r\nThere’s an R package for that!\r\nOne of R’s strengths is the vast amount of 3rd party code–packages–that can expand its functionality. There are over 15.000 packages on CRAN, R’s beloved package repository, and many more packages can be found on GitHub, Bioconductor, Neuroconductor, etc.\r\nThis series of blog post will unearth some of the lesser known gems: Packages that solve a very specific, perhaps obscure, problem. Packages that will make your life easier or make you scratch your head in wonder. Packages that are useful and packages that are just weird. We will have a look around the ginormous toolshed that is the R package ecosystem. Each episode will highlight another package, the power of R, and its amazing community.\r\nMake R scream with “beepr”\r\nToday we will look at packages that let R play notification sounds. This way R can notify you when your calculations are finished or have crashed, so you don’t have to continuously check on it and can instead browse Reddit read research papers.\r\nThe beepr package is a straightforward way to make R play a sound. Here’s how to install the package and play a sound:\r\n\r\n\r\ninstall.packages(\"beepr\")\r\nlibrary(beepr)\r\n\r\nSys.sleep(3) # replace this with your time-consuming calculation...\r\nbeep()\r\n\r\n\r\n\r\nYou can change the default “ping” sound to one of 9 alternatives, including the infamous Wilhelm scream.\r\n\r\n\r\nbeep(sound = \"wilhelm\")\r\n\r\n\r\n\r\nbeepr can also notify you when R throws an error. Just wrap your error-prone code in the beep_on_error() function like this:\r\n\r\n\r\nbeep_on_error(stop('I made a huge mistake!'))\r\n\r\n\r\n\r\nMake a Pomodoro timer with beepr\r\nWe can use beepr to build ourselves a rudimentary Pomodoro timer. Create a new R script pomodoro_timer.R and add the following code (I’m assuming you are using RStudio, otherwise the notification dialog will not work).\r\n\r\n\r\nlibrary(beepr) \r\n\r\ncounter = 0 # amount of finished pomodoros\r\n\r\nwhile(TRUE) {\r\n  # 25 minutes work\r\n  Sys.sleep(60 * 25)\r\n  counter <- counter + 1\r\n  beep(sound=\"mario\")\r\n  rstudioapi::showDialog(\"Pomodoro timer\",\r\n    sprintf(\"Pomodoro  nr. %i finished! Time to take a break!\", counter))\r\n  \r\n  # 5 minutes break, every 4th break is 15 minute long\r\n  break_dur <- ifelse(counter %% 4, 5, 15)\r\n  Sys.sleep(60 * break_dur)\r\n  beep(sound=\"wilhelm\")\r\n  rstudioapi::showDialog(\"Pomodoro timer\", \"Time to get back to work!\")\r\n}\r\n\r\n\r\n\r\nOf course, the sleep() function will block your R session. To run the code as a background process instead, you can use RStudio’s jobs API. Just run rstudioapi::jobRunScript('./pomodoro-timer.R') or source the pomodoro-timer.R script using the ‘Source as local job’ button in the top right corner of the source panel.\r\nThe job should appear in RStudio’s jobs panel, run in the background and remind you when it’s time to take a break.\r\n\r\n\r\nknitr::include_graphics(\"./images/screenshot-job.png\")\r\n\r\n\r\n\r\n\r\nFigure 1: The ‘source as local job’ button in RStudio.\r\n\r\n\r\n\r\n\r\n\r\nknitr::include_graphics(\"./images/screenshot-jobspanel.png\")\r\n\r\n\r\n\r\n\r\nFigure 2: The Jobs panel in RStudio.\r\n\r\n\r\n\r\n\r\nYou can learn more about beepr here.\r\nPlay rapper ad-libs with “BRRR”\r\nThe BRRR package’s main (and only?) function skrrrahh() plays sound bites from different rappers. There are 52 different ad-libs for all sorts of situations. To use the package run this:\r\n\r\n\r\nif(!require(devtools)) {install.packages(\"devtools\")}\r\ndevtools::install_github(\"brooke-watson/BRRR\")\r\nlibrary(\"BRRR\")\r\n\r\nskrrrahh(\"kendrick\")\r\n\r\n\r\n\r\nTo have your favourite artists cheer you on while you are coding, run the following code as an RStudio background job like we did above:\r\n\r\n\r\nwhile (TRUE) {\r\n  Sys.sleep(sample(5:60)) # randomly pause 5-60 seconds between cheers\r\n  skrrrahh(-1) # a non-existing number will produce a random ad-lib\r\n}\r\n\r\n\r\n\r\n\r\nYou can learn more about BRRR here.\r\nLook ma, no hands!\r\nIf you are on a Mac you can make R rap without any packages at all. Simply use the operating system’s built-in text-to-speech engine:\r\n\r\n\r\nsystem(\"say And if you don\\\\'t know, now you know!\") \r\n# note the double-backslash needed to escape the special character\r\n\r\n\r\n\r\nHas Biggie become an integral part of your analysis workflow or do you know other packages that can make R sing, dance, or swallow a sword? Tell me about it! [@drtobilotti](https://twitter.com/drtobilotti)\r\nPhoto by Clem Onojeghuo on Unsplash\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-01-11-theres-a-package-for-that-1/./images/hero.png",
    "last_modified": "2020-11-06T00:21:38+01:00",
    "input_file": "index.utf8.md"
  }
]
